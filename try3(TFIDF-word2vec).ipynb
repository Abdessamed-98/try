{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv(\"/datasets/quora/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105780</th>\n",
       "      <td>105780</td>\n",
       "      <td>174363</td>\n",
       "      <td>174364</td>\n",
       "      <td>How can I develop android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201841</th>\n",
       "      <td>201841</td>\n",
       "      <td>303951</td>\n",
       "      <td>174364</td>\n",
       "      <td>How can I create an Android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363362</th>\n",
       "      <td>363362</td>\n",
       "      <td>493340</td>\n",
       "      <td>493341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My Chinese name is Haichao Yu. What English na...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2                         question1  \\\n",
       "105780  105780  174363  174364    How can I develop android app?   \n",
       "201841  201841  303951  174364  How can I create an Android app?   \n",
       "363362  363362  493340  493341                               NaN   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "105780                                                NaN             0  \n",
       "201841                                                NaN             0  \n",
       "363362  My Chinese name is Haichao Yu. What English na...             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.isnull().any(axis=1)].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def text_to_word_list(text , split):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    #split to words for word2vec\n",
    "    if split :\n",
    "        text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = []\n",
    "question2 = []\n",
    "question1TF = []\n",
    "question2TF = []\n",
    "for x in df[\"question1\"]:\n",
    "    question1.append(text_to_word_list(x, True))\n",
    "    question1TF.append(text_to_word_list(x, False))\n",
    "for x in df[\"question2\"]:\n",
    "    question2.append(text_to_word_list(x, True))\n",
    "    question2TF.append(text_to_word_list(x, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "questions = question1 + question2\n",
    "\n",
    "# train model\n",
    "model = word2vec.Word2Vec(questions, size=10, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelw2v.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec.load('modelw2v.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exctract word2vec vectors\n",
    "vecs1 = []\n",
    "for qu in question1:\n",
    "    word_vec = []\n",
    "    for word in qu:\n",
    "        # word2vec\n",
    "        word_vec.append(model.wv[word])\n",
    "    vecs1.append(word_vec)\n",
    "df['q1_feats'] = list(vecs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs2 = []\n",
    "for qu2 in question2:\n",
    "    word_vec2 = []\n",
    "    for word in qu2:\n",
    "        # word2vec\n",
    "        word_vec2.append(model.wv[word])\n",
    "    vecs2.append(word_vec2)\n",
    "df['q2_feats'] = list(vecs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_feats</th>\n",
       "      <th>q2_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1.7473717, -2.6262953, -0.10161054, -0.87554...</td>\n",
       "      <td>[[1.7473717, -2.6262953, -0.10161054, -0.87554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1.7473717, -2.6262953, -0.10161054, -0.87554...</td>\n",
       "      <td>[[1.7473717, -2.6262953, -0.10161054, -0.87554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-2.3355067, 2.0692139, -0.8257057, 0.3185072...</td>\n",
       "      <td>[[-2.3355067, 2.0692139, -0.8257057, 0.3185072...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.16869572, 3.5913603, 0.35479644, 0.276689...</td>\n",
       "      <td>[[6.995065, 3.4047115, -2.1689236, 2.414899, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>[[2.1625907, -2.6822379, 2.4315636, -0.7801787...</td>\n",
       "      <td>[[2.1625907, -2.6822379, 2.4315636, -0.7801787...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>404285</td>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-2.3355067, 2.0692139, -0.8257057, 0.3185072...</td>\n",
       "      <td>[[-2.3355067, 2.0692139, -0.8257057, 0.3185072...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>404286</td>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-2.1759653, 1.8239492, 0.89487946, 1.6334667...</td>\n",
       "      <td>[[-0.86929, -1.8171616, 0.43591565, -0.6005701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1.7473717, -2.6262953, -0.10161054, -0.87554...</td>\n",
       "      <td>[[1.7473717, -2.6262953, -0.10161054, -0.87554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1.7473717, -2.6262953, -0.10161054, -0.87554...</td>\n",
       "      <td>[[-3.9164126, 4.0500646, 0.73007447, 1.7626686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1.7473717, -2.6262953, -0.10161054, -0.87554...</td>\n",
       "      <td>[[1.7473717, -2.6262953, -0.10161054, -0.87554...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404287 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "0            0       1       2   \n",
       "1            1       3       4   \n",
       "2            2       5       6   \n",
       "3            3       7       8   \n",
       "4            4       9      10   \n",
       "...        ...     ...     ...   \n",
       "404285  404285  433578  379845   \n",
       "404286  404286   18840  155606   \n",
       "404287  404287  537928  537929   \n",
       "404288  404288  537930  537931   \n",
       "404289  404289  537932  537933   \n",
       "\n",
       "                                                question1  \\\n",
       "0       What is the step by step guide to invest in sh...   \n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2       How can I increase the speed of my internet co...   \n",
       "3       Why am I mentally very lonely? How can I solve...   \n",
       "4       Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                   ...   \n",
       "404285  How many keywords are there in the Racket prog...   \n",
       "404286          Do you believe there is life after death?   \n",
       "404287                                  What is one coin?   \n",
       "404288  What is the approx annual cost of living while...   \n",
       "404289              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "0       What is the step by step guide to invest in sh...             0   \n",
       "1       What would happen if the Indian government sto...             0   \n",
       "2       How can Internet speed be increased by hacking...             0   \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4                 Which fish would survive in salt water?             0   \n",
       "...                                                   ...           ...   \n",
       "404285  How many keywords are there in PERL Programmin...             0   \n",
       "404286         Is it true that there is life after death?             1   \n",
       "404287                                  What's this coin?             0   \n",
       "404288  I am having little hairfall problem but I want...             0   \n",
       "404289      What is it like to have sex with your cousin?             0   \n",
       "\n",
       "                                                 q1_feats  \\\n",
       "0       [[1.7473717, -2.6262953, -0.10161054, -0.87554...   \n",
       "1       [[1.7473717, -2.6262953, -0.10161054, -0.87554...   \n",
       "2       [[-2.3355067, 2.0692139, -0.8257057, 0.3185072...   \n",
       "3       [[-0.16869572, 3.5913603, 0.35479644, 0.276689...   \n",
       "4       [[2.1625907, -2.6822379, 2.4315636, -0.7801787...   \n",
       "...                                                   ...   \n",
       "404285  [[-2.3355067, 2.0692139, -0.8257057, 0.3185072...   \n",
       "404286  [[-2.1759653, 1.8239492, 0.89487946, 1.6334667...   \n",
       "404287  [[1.7473717, -2.6262953, -0.10161054, -0.87554...   \n",
       "404288  [[1.7473717, -2.6262953, -0.10161054, -0.87554...   \n",
       "404289  [[1.7473717, -2.6262953, -0.10161054, -0.87554...   \n",
       "\n",
       "                                                 q2_feats  \n",
       "0       [[1.7473717, -2.6262953, -0.10161054, -0.87554...  \n",
       "1       [[1.7473717, -2.6262953, -0.10161054, -0.87554...  \n",
       "2       [[-2.3355067, 2.0692139, -0.8257057, 0.3185072...  \n",
       "3       [[6.995065, 3.4047115, -2.1689236, 2.414899, -...  \n",
       "4       [[2.1625907, -2.6822379, 2.4315636, -0.7801787...  \n",
       "...                                                   ...  \n",
       "404285  [[-2.3355067, 2.0692139, -0.8257057, 0.3185072...  \n",
       "404286  [[-0.86929, -1.8171616, 0.43591565, -0.6005701...  \n",
       "404287  [[1.7473717, -2.6262953, -0.10161054, -0.87554...  \n",
       "404288  [[-3.9164126, 4.0500646, 0.73007447, 1.7626686...  \n",
       "404289  [[1.7473717, -2.6262953, -0.10161054, -0.87554...  \n",
       "\n",
       "[404287 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 1.7473717 , -2.6262953 , -0.10161054, -0.8755403 , -1.1663448 ,\n",
      "        0.8059146 ,  2.0686438 ,  1.2114148 ,  0.88742393,  0.45057452],\n",
      "      dtype=float32), array([-0.86929   , -1.8171616 ,  0.43591565, -0.6005701 , -0.38657954,\n",
      "       -0.67453945,  0.24090974, -0.32868263,  1.8809551 ,  0.4018846 ],\n",
      "      dtype=float32), array([-0.53186184, -1.4571234 ,  1.7137733 , -1.5512898 ,  0.05082732,\n",
      "       -0.17809573,  0.3911812 ,  2.0384965 ,  0.7645675 ,  0.3621754 ],\n",
      "      dtype=float32), array([-0.48199895,  3.2713783 ,  2.0729063 , -1.4789608 , -0.03389227,\n",
      "        0.34500214,  1.5566995 ,  2.2249734 ,  0.25469473, -4.3693867 ],\n",
      "      dtype=float32), array([-2.2341025 ,  2.940374  ,  4.9096627 , -0.02052404,  0.8326176 ,\n",
      "       -3.298926  , -1.1585256 ,  0.69731516,  1.6589822 ,  3.3604858 ],\n",
      "      dtype=float32), array([-0.48199895,  3.2713783 ,  2.0729063 , -1.4789608 , -0.03389227,\n",
      "        0.34500214,  1.5566995 ,  2.2249734 ,  0.25469473, -4.3693867 ],\n",
      "      dtype=float32), array([ 0.43631157, -0.18210527, -0.4490396 ,  0.61069065, -1.6075056 ,\n",
      "       -2.330623  ,  0.829823  , -0.94461167,  1.4669119 , -1.7911094 ],\n",
      "      dtype=float32), array([-3.153897  ,  0.4402719 ,  2.4595597 ,  0.69081116,  1.3761957 ,\n",
      "       -3.7817616 ,  3.6577015 ,  4.954538  , -3.216608  ,  0.21817255],\n",
      "      dtype=float32), array([ 9.018448  ,  3.6554174 , -0.60406846, -0.9350298 ,  4.6467304 ,\n",
      "       -3.409334  ,  1.1191119 , -4.680518  , -0.45618182, -5.2457585 ],\n",
      "      dtype=float32), array([-2.0659647 , -0.94311756,  3.8067386 , -0.0621295 ,  2.0501423 ,\n",
      "       -3.7532833 , -0.12640065,  0.05085653,  0.45617822,  1.4826497 ],\n",
      "      dtype=float32), array([ 5.042094  ,  3.0289898 ,  0.18311438,  0.03426068, -0.47441354,\n",
      "       -1.5541714 ,  1.6956023 , -1.094844  ,  0.32714844, -1.3562241 ],\n",
      "      dtype=float32), array([ 4.551334  , -0.8752286 ,  1.7087041 , -3.2243745 ,  1.1911563 ,\n",
      "       -0.57738453,  1.9821845 , -1.5038106 , -4.0398817 , -1.1046575 ],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(df['q2_feats'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionsTF = question1TF + question2TF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a8d451114ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1650\u001b[0m         \"\"\"\n\u001b[1;32m   1651\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1058\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    350\u001b[0m                                                tokenize)\n\u001b[1;32m    351\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 352\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mtoken_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "questionsTF = question1TF + question2TF\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['q2_feats'], df['is_duplicate'], test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
